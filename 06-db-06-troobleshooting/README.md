# Домашнее задание к занятию "6.6. Troubleshooting"

## Задача 1

Перед выполнением задания ознакомьтесь с документацией по [администрированию MongoDB](https://docs.mongodb.com/manual/administration/).

Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD операция в MongoDB и её 
нужно прервать. 

Вы как инженер поддержки решили произвести данную операцию:
- напишите список операций, которые вы будете производить для остановки запроса пользователя
- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB

В первую очередь необходимо найти данную операцию - db.currentOp(). После можно воспользоваться командой db.killOp(), чтобы прервать выполнение команды. Для того, чтобы не попадать в такую ситуацию, возможно использование параметра maxTimeMS() для запросов CRUD в MongoDB.

## Задача 2

Перед выполнением задания познакомьтесь с документацией по [Redis latency troobleshooting](https://redis.io/topics/latency).

Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. 
Причем отношение количества записанных key-value значений к количеству истёкших значений есть величина постоянная и
увеличивается пропорционально количеству реплик сервиса. 

При масштабировании сервиса до N реплик вы увидели, что:
- сначала рост отношения записанных значений к истекшим
- Redis блокирует операции записи

Как вы думаете, в чем может быть проблема?

В Redis есть два способа очистить просроченные записи: "ленивый" и "активный". В случае с ленивым - просроченные записи запрашиваются командой, активный способ - повторяется каждые 100 миллисекунд и проводит записи в состояние устаревшие, затем данные записи исключаются. ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP по умолчанию имеет значение 20, таким образом за раз можно пометить и очистить около 200 устаревших записей. Процесс проверки зациклится и мы ощутим задержки, а потом и вовсе не будут приниматься данные на запись, если появятся истекшие записи более 25% по отношению ко всем. В данном случае как раз так и получается. Такой подход необходим, чтобы не использовать слишком много памяти для ключей, срок действия которых уже истек.

## Задача 3

Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей, в таблицах базы,
пользователи начали жаловаться на ошибки вида:
```python
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```

Как вы думаете, почему это начало происходить и как локализовать проблему?

Какие пути решения данной проблемы вы можете предложить?

Проблема заключается в том, что данные BLOB больше, чем значение max_allowed_packet, чтобы избежать подобных вещей следует увеличить значение max_allowed_packet

## Задача 4

Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с 
большим объемом данных лучше, чем MySQL.

После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:

`postmaster invoked oom-killer`

Как вы думаете, что происходит?
Уничтожение в postgress главного управляющего процесса postmaster из-за нехватки памяти.

Как бы вы решили данную проблему?

В Linux механизм виртуальной памяти по умолчанию работает не оптимально для Postgres. Вследствие того, что ядро выделяет память в чрезмерном объёме, оно может уничтожить главный управляющий процесс Postgres (postmaster), если при выделении памяти процессу Postgres или другому процессу виртуальная память будет исчерпана.
```
service postgres restart
```
Работать с ядром ОС:

включить режим строгого выделения памяти, воспользовавшись sysctl:
```
sysctl -w vm.overcommit_memory=2
```
либо поместив соответствующую запись в /etc/sysctl.conf
изменить связанный параметр vm.overcommit_ratio
документация ядра https://www.kernel.org/doc/Documentation/vm/overcommit-accounting

Другой подход, который можно применить (возможно, вместе с изменением vm.overcommit_memory), заключается в исключении процесса postmaster из числа возможных жертв при нехватке памяти. Для этого нужно задать для свойства поправка очков OOM этого процесса значение -1000. Проще всего это можно сделать, выполнив:
```
echo -1000 > /proc/self/oom_score_adj
```
в скрипте запуска управляющего процесса непосредственно перед тем, как запускать postmaster. Заметьте, что делать это надо под именем root, иначе ничего не изменится; поэтому проще всего вставить эту команду в стартовый скрипт, принадлежащий пользователю root. Если вы делаете это, вы также должны установить в данном скрипте эти переменные окружения перед запуском главного процесса:
```
export PG_OOM_ADJUST_FILE=/proc/self/oom_score_adj
export PG_OOM_ADJUST_VALUE=0
```
С такими параметрами дочерние процессы главного будут запускаться с обычной, нулевой поправкой очков OOM, так что при необходимости механизм OOM сможет уничтожать их. Вы можете задать и другое значение для PG_OOM_ADJUST_VALUE, если хотите, чтобы дочерние процессы исполнялись с другой поправкой OOM. (PG_OOM_ADJUST_VALUE также можно опустить, в этом случае подразумевается нулевое значение.) Если вы не установите PG_OOM_ADJUST_FILE, дочерние процессы будут работать с той же поправкой очков OOM, которая задана для главного процесса, что неразумно, так всё это делается как раз для того, чтобы главный процесс оказался на особом положении;

Не смешивать работу СУБД с другими сервисами;

Увеличить объём пространства подкачки, так как уничтожение процессов при нехватке памяти происходит только когда заканчивается и физическая память, и место в пространстве подкачки;

Может помочь уменьшение конфигурационных параметров, связанных с памятью, а именно shared_buffers, work_mem и hash_mem_multiplier;

Проблема может возникать, потому что разрешено слишком много подключений к самому серверу баз данных. Чаще всего в такой ситуации стоит уменьшить число подключений max_connections и организовать внешний пул соединений;

source:
https://postgrespro.ru/docs/enterprise/13/kernel-resources

---

### Как cдавать задание

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---
